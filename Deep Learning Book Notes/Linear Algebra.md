## 2.1 Scalars, Vectors, Matrices and Tensors

### Scalars:
A scalar is a single number.

### Vectors
A vector is an algebric structure, mostly described as a list of scalars.  
Example of vectors:
* In Phisycs: An arrow pointing to a direction

### Matrices
2D vector, containing scalars (basically a vector of vectors).  
In geometry a matrix represents a transformation of a vector space. This matrix multiplied with a vector gives the coresponding vector in the transformed space.

### Tensor
an N-Dimensional array of scalars

## 2.2 Multiplying Matrices and Vectors
* Normal Multiplication of matrices: $$ C_{i,j} = \sum_{k} A_{i,k} * B_{k,j} $$
* Hadamard Product (Element wise): $$ A \odot B $$
* Dot Product (Vectors) - result is a scalar, basically normal multiplication of matrices: $$ x^\mathsf{T}y $$
* Distributivity: $$ A(B + C) = AB + AC $$
* Asociativity: $$ A(BC) = (AB)C $$
* Transpose: $$ (AB)^\mathsf{T} = B^\mathsf{T}A^\mathsf{T} $$

## 2.3 Identity and Inverse Matrices
* Identity: $$ AI_n = I_nA = A $$
* Inverse: $$ A^{-1}A = AA^{-1} = I_n $$

## 2.4 Linear Dependance and Span

### Span
The list of vectors that can be computed as a linear combination of any elements of a set of vectors.  
In geometry it can be seen as the total space generated by a set of vectors.

### Linear Dependence
A set of vectors is linear dependent if at least one of those vectors can be written as a linear combination of the others: $$ v^{(i)} = \sum_{k\neq i} a_kv^{(k)} $$  
Any set that doesn't contain any such vector is called linear independent

## 2.5 Norms
Mainly described as the distance between the origin and the point.  
Must respect 3 properties:  
* $$ f(x) = 0 => x = 0 $$
* $$ f(x + y) \leq f(x) + f(y) \text{  (the triangle inequality)} $$
* $$ \forall \alpha \in \mathbb{R} , f(\alpha x) = |\alpha|f(x) $$
